#!/bin/bash
#SBATCH --job-name=dino_swin_tiny_w7x7_300_bs96
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=4
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 3-11:59:59
#SBATCH --exclusive
#SBATCH --cpus-per-task=18
#SBATCH -o dino_swin_tiny_w7x7_300_bs96.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak



nohup python -m torch.distributed.launch --nproc_per_node=1 main_dino.py --arch swin_tiny  --teacher_temp 0.07 --warmup_teacher_temp_epochs 30 --norm_last_layer false  \
--data_path /datadrive_c/imagenet/train --output_dir /datadrive_c/ssl/swin_tiny_300/ \
--batch_size_per_gpu 64 --epochs 300  \
--use_dense_prediction False --cfg experiments/imagenet/swin/swin_tiny_patch4_window7_224.yaml > swin_tiny_300.txt 2>&1 &



 source deactivate
