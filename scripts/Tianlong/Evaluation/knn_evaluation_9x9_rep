#!/bin/bash
#SBATCH --job-name=knn_slak_9x9_300_100epochs
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 0-0:59:59
#SBATCH --cpus-per-task=18
#SBATCH -o knn_slak_9x9_300_100epochs.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak

python -m torch.distributed.launch --nproc_per_node=1 eval_knn.py --data_path  /datadrive_c/imagenet/ --batch_size_per_gpu 256 \
--arch SLaK_tiny --kernel_size 9 9 9 9 3 --bn True --pretrained_weights /datadrive_c/ssl/slak_9_bn_300_tiny_rep3/checkpoint.pth



source deactivate