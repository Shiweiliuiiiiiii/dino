#!/bin/bash
#SBATCH --job-name=linear_swin_patch4_window7_300_100epochs
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1
#SBATCH --gpus=1
#SBATCH -t 2-0:59:59
#SBATCH --cpus-per-task=18
#SBATCH -o linear_swin_patch4_window7_300_100epochs.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak


python -m torch.distributed.launch --nproc_per_node=1 --master_port=12222 eval_linear.py --data_path /projects/2/managed_datasets/imagenet/ \
--arch swin_tiny --pretrained_weights /projects/0/prjste21060/projects/dino/dino_swin_tiny_patch4_window7_300_96/checkpoint0100.pth \
--cfg experiments/imagenet/swin/swin_tiny_patch4_window7_224.yaml \
--output_dir /projects/0/prjste21060/projects/dino/dino_swin_tiny_100_/linear/ --checkpoint_key teacher \
--batch_size_per_gpu 256 --n_last_blocks 4 --num_labels 1000 MODEL.NUM_CLASSES 0

source deactivate