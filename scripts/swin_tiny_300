#!/bin/bash
#SBATCH --job-name=dino_swin_tiny_w7x7_300_bs96_resume1
#SBATCH -p gpu
#SBATCH -N 1
#SBATCH --ntasks-per-node=4
#SBATCH --gpus-per-node=4
#SBATCH --gpus=4
#SBATCH -t 4-11:59:59
#SBATCH --exclusive
#SBATCH --cpus-per-task=18
#SBATCH -o dino_swin_tiny_w7x7_300_bs96_resume1.out

source /home/sliu/miniconda3/etc/profile.d/conda.sh
source activate slak



python -m torch.distributed.launch --nproc_per_node=1 main_dino.py --arch swin_tiny  --teacher_temp 0.07 --warmup_teacher_temp_epochs 30 --norm_last_layer false  \
--data_path /projects/2/managed_datasets/imagenet/train --output_dir /projects/0/prjste21060/projects/dino/dino_swin_tiny_patch4_window7_300_96/ \
--batch_size_per_gpu 96 --epochs 300  \
--warmup_epochs 10  --norm_last_layer True \
--use_dense_prediction False --cfg experiments/imagenet/swin/swin_tiny_patch4_window7_224.yaml



 source deactivate
